{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab__ANPL__yolov3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I_FXY-bftgC"
      },
      "source": [
        "\n",
        "本程式碼請參考「[在 Colab 上利用 Yolov3 框架和自有標住資料來訓練自己的物件辨識系統](http://bit.ly/2OAfpq0)」 。\n",
        "\n",
        "# 這篇文章\n",
        "訓練一個能偵測圖片中車牌的模型。\n",
        "\n",
        "* 利用 Colab 128G RAM GPU 來訓練你的 Yolo3 模型\n",
        "* 掛載 Google Drive 檔案到 Colab 檔案系統中\n",
        "* 將 PASCAL VOC 標籤格式轉換成 Yolo 用的標籤格式\n",
        "* 產生 Yolo 訓練需要的 cfg 設定檔案\n",
        "* 將訓練後的 weight 檔案同步至 Google Drive 中，避免遺失\n",
        "* 如何利用 weight 檔案來辨識圖片中的內容\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEXkY-lagdBF"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAjezpOEilTY"
      },
      "source": [
        "## 將 Google Drive 掛載到 Colab 目錄下\n",
        "\n",
        "掛載 Google Drive 的好處是不用每次都手動上傳或下載檔案，而且還能讓訓練好的模型檔案自動保存到 Google Drive。這樣就不會因為 Colab 中斷後就必須從頭訓練。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnqbZSdu0jjk"
      },
      "source": [
        "# 將 Google Drive 掛載到 Colab 目錄下\n",
        "from google.colab import drive\n",
        "drive.mount('/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U96J-wAdxQY_"
      },
      "source": [
        "# 準備資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBVY0kfGxCoP"
      },
      "source": [
        "# 建立資料夾\n",
        "%cd /content \n",
        "!mkdir /content/ANPR\n",
        "!mkdir /content/ANPR/detection\n",
        "!mkdir /content/ANPR/labels\n",
        "!mkdir /content/ANPR/images/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4NybPaCPWL2"
      },
      "source": [
        "%cd /drive/MyDrive \n",
        "# !ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk45AujCNt_j"
      },
      "source": [
        "%cd /content/ANPR/images/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJETM-JNEzxT"
      },
      "source": [
        "# 先將訓練圖片壓縮檔放在雲端，從雲端解壓縮至colab\n",
        "!unzip /drive/MyDrive/images.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9irZfjVNuhx"
      },
      "source": [
        "%cd /content/ANPR/labels/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8w4EoqgEzum"
      },
      "source": [
        "# 先將訓練圖片的xml壓縮檔放在雲端，從雲端解壓縮至colab\n",
        "!unzip /drive/MyDrive/annotations.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx16w5n8EzoQ"
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keKBT0IZi-gs"
      },
      "source": [
        "## 定義後來會用到的檔案路徑\n",
        "\n",
        "路徑分為保存在 Colab 的，每次 Colab 被重置後就會消失。所以只放一些不重要的東西。\n",
        "保存在 Google Drive 的檔案就是會被保存下來的，即使 Colab 被重置後，也不會消失；我們會把重要的東西存在這，例如設定檔、訓練到一半的模型等。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIBZ9vWTCkNo"
      },
      "source": [
        "# 設定路徑變數\n",
        "LOCAL_IMAGES_DIR_PATH = \"/content/ANPR/images\"\n",
        "LOCAL_LABELS_DIR_PATH = \"/content/ANPR/labels\"\n",
        "LOCAL_YOLOS_DIR_PATH = \"/content/ANPR/yolos\"\n",
        "LOCAL_CFG_DIR_PATH = \"/content/ANPR/cfg\"\n",
        "\n",
        "GDRIVE_APP_BASE_DIR_REMOTE_PATH = \"/drive/My\\ Drive/train_yolo_with_custom_dataset_on_colab_101\"\n",
        "GDRIVE_APP_BASE_DIR_PATH = \"/content/app\"\n",
        "GDRIVE_WEIGHTS_DIR_PATH = GDRIVE_APP_BASE_DIR_PATH+\"/weights\"\n",
        "GDRIVE_CFG_DIR_PATH = GDRIVE_APP_BASE_DIR_PATH+\"/cfg\"\n",
        "\n",
        "GITHUB_CODEBASE_DIR_PATH = \"/content/train_yolo_with_custom_dataset_on_colab_101\"\n",
        "\n",
        "GDRIVE_DARKNET_BIN_FILE_PATH = GITHUB_CODEBASE_DIR_PATH+\"/darknet\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T8AKZiy1zep"
      },
      "source": [
        "# load sample codes\n",
        "%cd /content\n",
        "!git clone https://github.com/wallat/train_yolo_with_custom_dataset_on_colab_101.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiDkR-bmmSOm"
      },
      "source": [
        "# build the link to avoiding type in long path name everytime\n",
        "# 介紹ln指令: https://blog.gtwang.org/linux/linux-ln-command-tutorial-examples/\n",
        "!ln -fs {GDRIVE_APP_BASE_DIR_REMOTE_PATH} {GDRIVE_APP_BASE_DIR_PATH}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc2Nj_7rB66Z"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# clean folders\n",
        "# 介紹shutil.rmtree指令: https://www.wongwonggoods.com/python/python_file_process/python-shutil-rmtree/\n",
        "shutil.rmtree(LOCAL_CFG_DIR_PATH, ignore_errors=True)\n",
        "shutil.rmtree(LOCAL_YOLOS_DIR_PATH, ignore_errors=True)\n",
        "\n",
        "# create folders\n",
        "os.makedirs(GDRIVE_APP_BASE_DIR_REMOTE_PATH.replace(\"\\ \", \" \"), exist_ok=True)\n",
        "os.makedirs(GDRIVE_CFG_DIR_PATH, exist_ok=True)\n",
        "os.makedirs(GDRIVE_WEIGHTS_DIR_PATH, exist_ok=True)\n",
        "\n",
        "os.makedirs(LOCAL_CFG_DIR_PATH, exist_ok=True)\n",
        "os.makedirs(LOCAL_YOLOS_DIR_PATH, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4I8XuV0mfxG"
      },
      "source": [
        "## 擷取出所有的標籤名稱\n",
        "\n",
        "由於 darknet 框架會將物體名字全部轉成數字，我們需要先將物體名字全部擷取出來存在一份檔案中，當作之後的對照表。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6vyhMZEOybf"
      },
      "source": [
        "# Convert VOC xmls into Yolo's format\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "\n",
        "labels = set()\n",
        "for path in glob.glob(os.path.join(LOCAL_LABELS_DIR_PATH, \"*.xml\")):\n",
        "    with open(path, 'r') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # extract label names\n",
        "    matches = re.findall(r'<name>([\\w_]+)<\\/name>', content, flags=0)\n",
        "    labels.update(matches)\n",
        "    \n",
        "# write label into file\n",
        "with open(os.path.join(GDRIVE_CFG_DIR_PATH, \"obj.names\"), 'w') as f:\n",
        "    f.write(\"\\n\".join(labels))\n",
        "\n",
        "print(f'Read in {len(labels)} labels: {\", \".join(labels)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVlFExg6Gnap"
      },
      "source": [
        "%cd /content/ANPR/images/\n",
        "import os\n",
        "\n",
        "# 先取得該檔案夾內所有的檔案名稱\n",
        "def get_list():\n",
        "    all_name = os.listdir()\n",
        "    return all_name\n",
        "\n",
        "# 對所有的檔案名稱做 for 迴圈，訂定你的命名規則\n",
        "for i in get_list():\n",
        "    path = i.replace('.png','.jpg') \n",
        "    # 如果你的檔案夾裡面不只有照片，也有其他類型的檔案，用 if 把照片挑出來\n",
        "    os. rename(i , path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uUZXq-Lzzkk"
      },
      "source": [
        "## 將 VOC 格式的標記資料轉成 YOLO 的標記資料\n",
        "\n",
        "Yolo 不是使用標準的格式，原本的 VOC 標記格式需要轉換後才能使用在 darkent 框架上。\n",
        "這邊就不詳細解釋如何轉換，對如何轉換的詳細規格可以參考 Yolo 官網 。我們直接使用我從 convert2Yolo 套件中擷取出來的片段程式碼來執行轉換，並把轉換的結果都放到 `/content/ANPR/yolos` 目錄中。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiGMipcozWPa"
      },
      "source": [
        "import sys\n",
        "sys.path.append(GITHUB_CODEBASE_DIR_PATH)\n",
        "\n",
        "from Format import VOC, YOLO\n",
        "\n",
        "voc = VOC()\n",
        "yolo = YOLO(os.path.join(GDRIVE_CFG_DIR_PATH, \"obj.names\"))\n",
        "\n",
        "flag, data = voc.parse(LOCAL_LABELS_DIR_PATH)\n",
        "flag, data = yolo.generate(data)\n",
        "\n",
        "flag, data = yolo.save(data,\n",
        "    save_path=LOCAL_YOLOS_DIR_PATH,\n",
        "    img_path=LOCAL_IMAGES_DIR_PATH, img_type=\".jpg\", manipast_path=\"./\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMfMvmN367pF"
      },
      "source": [
        "# copy images into yolos folder\n",
        "# !find $LOCAL_IMAGES_DIR_PATH -name \"*.jpg\" -exec cp {} /content/ANPR/yolos \\;\n",
        "\n",
        "# from distutils.dir_util import copy_tree\n",
        "# copy_tree(LOCAL_IMAGES_DIR_PATH, LOCAL_YOLOS_DIR_PATH)\n",
        "\n",
        "!cp {LOCAL_IMAGES_DIR_PATH}/*.jpg {LOCAL_YOLOS_DIR_PATH}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSHUro0RG05I"
      },
      "source": [
        "%cd /content/ANPR/yolos/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4FhRWwuSfbY"
      },
      "source": [
        "## 準備訓練用的設定檔\n",
        "\n",
        "* `obj.names`：所有的物體標籤名稱，每一行一個。\n",
        "* `yolov3.cfg`：darknet 網路的設定檔，描述每一層網路應該要如何建立，以及建立多少 node 等。\n",
        "***yolov3.cfg裡面有些數值需要根據你的訓練資料來個別設定 => [yolo] 中的classes=類別數量；[yolo] 前一個 [convolutional] 中的filters=(5+classes)x3，總共有三個 [yolo] 要改。另外max_batches預設4000，可以自行調整迭代次數。**\n",
        "* `train.txt` `test.txt` ：這兩個檔案告訴 darknet 要到哪個路徑下找到訓練用的圖片。\n",
        "* `obj.data`：darknet 的主要設定檔案，告訴 darknet 其他的設定檔路徑。darknet 會一一去讀取其他的檔案。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyAmNKZb_yM1"
      },
      "source": [
        "# create the cfg file\n",
        "!cp {GITHUB_CODEBASE_DIR_PATH}/darknet_cfg/yolov3.cfg {GDRIVE_CFG_DIR_PATH}/yolov3.cfg\n",
        "\n",
        "# fetch label_names\n",
        "with open(os.path.join(GDRIVE_CFG_DIR_PATH, \"obj.names\"), 'r') as f:\n",
        "  f_content = f.read()\n",
        "label_names = f_content.strip().splitlines()\n",
        "print(len(label_names))\n",
        "\n",
        "# update the cfg file\n",
        "# TODO 不確定這段是否有功能，目前理解這段是要去更改cfg內容，但感覺沒起到作用，需要手動更改參數。\n",
        "with open(os.path.join(GDRIVE_CFG_DIR_PATH, \"yolov3.cfg\"), 'r') as f:\n",
        "  content = f.read()\n",
        "with open(os.path.join(GDRIVE_CFG_DIR_PATH, \"yolov3.cfg\"), 'w') as f:\n",
        "  num_max_batches = len(label_names)*2000\n",
        "  content = content.replace(\"%NUM_CLASSES%\", str(len(label_names)))\n",
        "  content = content.replace(\"%NUM_MAX_BATCHES%\", str(num_max_batches))\n",
        "  content = content.replace(\"%NUM_MAX_BATCHES_80%\", str(int(num_max_batches*0.8)))\n",
        "  content = content.replace(\"%NUM_MAX_BATCHES_90%\", str(int(num_max_batches*0.9)))\n",
        "  content = content.replace(\"%NUM_CONVOLUTIONAL_FILTERS%\", str((len(label_names)+5)*3))\n",
        "\n",
        "  f.write(content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cb7KN85Iccf"
      },
      "source": [
        "# create train and test files\n",
        "import random\n",
        "import glob\n",
        "\n",
        "txt_paths = glob.glob(os.path.join(LOCAL_YOLOS_DIR_PATH, \"*.txt\"))\n",
        "\n",
        "random.shuffle(txt_paths)\n",
        "num_train_images = int(len(txt_paths)*0.8)\n",
        "\n",
        "assert num_train_images>0, \"There's no training images in folder %s\" % (LOCAL_YOLOS_DIR_PATH)\n",
        "\n",
        "with open(os.path.join(GDRIVE_CFG_DIR_PATH, \"train.txt\"), 'w') as f:\n",
        "  for path in txt_paths[:num_train_images]:\n",
        "    f.write(\"%s/%s\\n\" % (LOCAL_YOLOS_DIR_PATH, os.path.basename(path).replace(\".txt\", \".jpg\")))\n",
        "with open(os.path.join(GDRIVE_CFG_DIR_PATH, \"test.txt\"), 'w') as f:\n",
        "  for path in txt_paths[num_train_images:]:\n",
        "    f.write(\"%s/%s\\n\" % (LOCAL_YOLOS_DIR_PATH, os.path.basename(path).replace(\".txt\", \".jpg\")))\n",
        "\n",
        "# create obj\n",
        "with open(os.path.join(GDRIVE_CFG_DIR_PATH, \"obj.data\"), 'w') as f:\n",
        "  f.write(\"classes=%d\\n\" % (len(label_names)))\n",
        "  f.write(\"train=%s/train.txt\\n\" % (GDRIVE_CFG_DIR_PATH))\n",
        "  f.write(\"valid=%s/test.txt\\n\" % (GDRIVE_CFG_DIR_PATH))\n",
        "  f.write(\"names=%s/obj.names\\n\" % (GDRIVE_CFG_DIR_PATH))\n",
        "  f.write(\"backup=%s\\n\" % (GDRIVE_WEIGHTS_DIR_PATH))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KLA9fOHSvAg"
      },
      "source": [
        "## 準備 darkent 執行檔\n",
        "\n",
        "我們直接從之前已經編譯好的檔案複製過來就好，不用每次都重頭編譯那實在是太~花~時~間~了~。編譯的方法請見 「[如何在 Colab 安裝 Darknet 框架訓練 YOLO v3 物件辨識並且最佳化 Colab 的訓練流程](http://bit.ly/33XjcEu)」這邊文章。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl6yvB81G7AT"
      },
      "source": [
        "# copy the pretrained darknet bin file\n",
        "!cp {GDRIVE_DARKNET_BIN_FILE_PATH} /content/\n",
        "assert os.path.isfile(\"/content/darknet\"), 'Cannot copy from %s to /content' % (GDRIVE_DARKNET_BIN_FILE_PATH)\n",
        "\n",
        "!chmod +x /content/darknet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtKSu2kRTFfG"
      },
      "source": [
        "## （可選）使用 darknet 預先訓練的基底模型\n",
        "\n",
        "Darknet 也好心的提供了預先訓練的模型，以此為基底，可以讓後來的訓練比較快達到較好的辨識率。但前提是你的圖片都是常見的圖片，例如一般照片、場景照片等；如果是一些遊戲畫面很少見的，從 0 開始訓練可能會達到比較好的效果。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Pd4fjskYnak"
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znh4uODyAYnU"
      },
      "source": [
        "# Use the pre-trained weights to speed up the training speed\n",
        "!wget https://pjreddie.com/media/files/darknet53.conv.74"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93nCcBTEUM3r"
      },
      "source": [
        "# 終於可以開始訓練模型了～\n",
        "\n",
        "上面的步驟看起來很多，但其實只要寫好一次，之後每次訓練時只要換上自己要的資料夾，然後按 `Run all` 就可以了。\n",
        "\n",
        "這邊提供兩條指令：\n",
        "\n",
        "1. 是從 YOLO Pre-trained model 開始訓練，如果你的資料集是一般照片，那用這個效果會比較好。\n",
        "\n",
        "2. 是從上次訓練的中斷點繼續往下訓練；指令會讀取資料夾內的 weight 檔案，從上次中斷點繼續訓練下去。適合從 0 開始訓練或是被 Colab 中斷後重新開始訓練。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOjLLa-DGDmv"
      },
      "source": [
        "# train the model\n",
        "\n",
        "# 第一次訓練用以下指令\n",
        "!./darknet detector train {GDRIVE_CFG_DIR_PATH}/obj.data {GDRIVE_CFG_DIR_PATH}/yolov3.cfg darknet53.conv.74  -dont_show | grep \"avg loss\"\n",
        "\n",
        "# 已經有先前訓練的weight檔案，想繼續訓練下去，用以下指令\n",
        "# !./darknet detector train {GDRIVE_CFG_DIR_PATH}/obj.data {GDRIVE_CFG_DIR_PATH}/yolov3.cfg {GDRIVE_WEIGHTS_DIR_PATH}/yolov3_last.weights  -dont_show | grep \"avg loss\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BflsdxKctsk5"
      },
      "source": [
        "## **完成以上程式碼即完成安裝手冊第四個步驟，以下程式碼僅驗證模型。**\n",
        "================================================================================"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dllBtLuzUi3I"
      },
      "source": [
        "%cd /content/train_yolo_with_custom_dataset_on_colab_101/to_detect_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiaSndc6Vjvo"
      },
      "source": [
        "# 載入測試資料 (需放測試資料到雲端，並命名為test.zip)\n",
        "!unzip /drive/MyDrive/test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3okNdY7MWZjQ"
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcj577W0iCoR"
      },
      "source": [
        "# 檢視訓練成果\n",
        "\n",
        "檢測圖片時，我們只需要 `obj.names`, `yolov3.cfg` 以及 weights 檔就夠。我們可以直接利用 Opencv 內建的 darknet 來讀取網路並產生出預測。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwdKXMy5ip7i"
      },
      "source": [
        "TO_DETECTING_IMAGE_DIR_PATH = GITHUB_CODEBASE_DIR_PATH+\"/to_detect_images\"\n",
        "\n",
        "# Use python to read \n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "\n",
        "\n",
        "def detecting_one_image(net, output_layers, img):\n",
        "  # Detecting objects\n",
        "  # cv::dnn::blobFromImage (InputArray image, double scalefactor=1.0, const Size &size=Size(), const Scalar &mean=Scalar(), bool swapRB=false, bool crop=false, int ddepth=CV_32F)\n",
        "  blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "  net.setInput(blob)\n",
        "  outs = net.forward(output_layers)\n",
        "\n",
        "  return outs\n",
        "\n",
        "# Load Yolo\n",
        "net = cv2.dnn.readNet(GDRIVE_WEIGHTS_DIR_PATH+\"/yolov3_last.weights\", GDRIVE_CFG_DIR_PATH+\"/yolov3.cfg\")\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "# Load label names\n",
        "with open(GDRIVE_CFG_DIR_PATH+\"/obj.names\", \"r\") as f:\n",
        "  classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# Generate display colors\n",
        "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "\n",
        "for fpath in glob.glob(os.path.join(TO_DETECTING_IMAGE_DIR_PATH, \"*.jpg\")):\n",
        "  print(\"fpath\", fpath)\n",
        "\n",
        "  # Loading image\n",
        "  img = cv2.imread(fpath)\n",
        "  height, width, channels = img.shape\n",
        "\n",
        "  if width>800: # resize for display purpose\n",
        "    dim = (800, int(800*height/width))\n",
        "    img = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
        "    height, width, channels = img.shape\n",
        "\n",
        "  outs = detecting_one_image(net, output_layers, img)\n",
        "\n",
        "  # Showing informations on the screen\n",
        "  for out in outs:\n",
        "    for detection in out:\n",
        "      scores = detection[5:]\n",
        "      class_id = np.argmax(scores)\n",
        "      confidence = scores[class_id]\n",
        "      if confidence > 0.3:\n",
        "        # Object detected\n",
        "        center_x = int(detection[0] * width)\n",
        "        center_y = int(detection[1] * height)\n",
        "        w = int(detection[2] * width)\n",
        "        h = int(detection[3] * height)\n",
        "\n",
        "        # Rectangle coordinates\n",
        "        x = int(center_x - w / 2)\n",
        "        y = int(center_y - h / 2)\n",
        "\n",
        "        label = \"(%.2f) %s\" % (confidence, classes[class_id])\n",
        "\n",
        "        cv2.rectangle(img, (x, y), (x + w, y + h), colors[class_id], 2)\n",
        "        cv2.putText(img, label, (x, y+h-5), cv2.FONT_HERSHEY_PLAIN, 1, colors[class_id], 1)\n",
        "\n",
        "  cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwmEsW064H_F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}